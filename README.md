# AccANN
A compiler from AI model to RTL (Verilog) accelerator in FPGA hardware with auto design space exploration for AdderNet.

<div align=center><img src="./img/figure/figure1.png"></div>
Fig 1. Visualization of features in AdderNets and CNNs. <sup>[1]</sup>
<br>
<div align=center><img src="./img/figure/figure2.png"></div>
Fig 2. Visualization of features in different neural networks on MNIST dataset. <sup>[3]</sup>

## Related Works

[1] AdderNet: Do We Really Need Multiplications in Deep Learning? Hanting Chen, Yunhe Wang, Chunjing Xu, Boxin Shi, Chao Xu, Qi Tian, Chang Xu. CVPR, 2020. [[paper](https://arxiv.org/abs/1912.13200) | [code](https://github.com/huawei-noah/AdderNet)]

[2] AdderSR: Towards Energy Efficient Image Super-Resolution. Dehua Song, Yunhe Wang, Hanting Chen, Chang Xu, Chunjing Xu, Dacheng Tao. Arxiv, 2020. [[paper](https://arxiv.org/abs/2009.08891) | code]

[3] ShiftAddNet: A Hardware-Inspired Deep Network. Haoran You, Xiaohan Chen, Yongan Zhang, Chaojian Li, Sicheng Li, Zihao Liu, Zhangyang Wang, Yingyan Lin. NeurIPS, 2020.

[4] Kernel Based Progressive Distillation for Adder Neural Networks. Yixing Xu, Chang Xu, Xinghao Chen, Wei Zhang, Chunjing XU, Yunhe Wang. NeurIPS, 2020. [[paper](https://arxiv.org/abs/2009.13044) | [code]()]

[5] GhostNet: More Features from Cheap Operations [[paper](https://arxiv.org/abs/1911.11907) | [code](https://github.com/huawei-noah/ghostnet)]

[6] DNNBuilder: an Automated Tool for Building High-Performance DNN Hardware Accelerators for FPGAs [[paper](https://docs.wixstatic.com/ugd/c50250_77e06b7f02b44eacb76c05e8fbe01e08.pdf) | [code](https://github.com/IBM/AccDNN)]
